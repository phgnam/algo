Hey everybody, welcome to Systems Expert.
in this video we're gonna cover MapReduce.
As with many other systems design topics, MapReduce is pretty simple at face value, but it gets very complicated once you dive into its details.
The good news is that once again as with many other systems design topics, in the context of systems design interviews, what you need to know about MapReduce is actually relatively straightforward, relatively simple and it doesn't touch too much on those very complicated details.
Now in order to fully understand what MapReduce really is, we have to go back in history all the way to the early 2000s when Google engineers were faced with a challenge, and the challenge that they were faced with was that they were dealing with very, very large data sets.And as you might imagine, they had to process these data sets, and as you can imagine there's only so much vertical scaling that you can do when you're dealing with large data sets.
So what I'm getting at here is that when you have very large data sets, you eventually have to horizontally scale your system, you have to add machines to your system.
So these Google engineers had to process large data sets that were stored across hundreds if not thousands of machines.
And if there's one thing that we've really tried to make clear throughout all the videos that we have here on Systems Expert, it's that when you're dealing with a distributed system, otherwise simple tasks like processing a data set become very difficult.
Processing a data set that's stored across hundreds or thousands of machines is a very difficult, it's a non-trivial task, you have to paralyse the processing across these hundreds or thousands of machines, you have to handle failures like network partitions or machine failures.
All of these things are difficult and these Google engineers had to figure out a way to process these large data sets in a distributed setting, efficiently, quickly and in a fault-tolerant manner, and so that's where MapReduce comes into play.
In 2004 two very well-known Google engineers released a white paper on the MapReduce model, and by the way here taking a quick pause, if you're particularly interested in MapReduce, I would highly encourage you to read or at least skim through that white paper, you can find it online just Google MapReduce White Paper, it's a pretty short read, it's not easy, it's certainly pretty complex, they dive into the details and it's gonna be a tough read, but it's a very good resource if you're really interested in MapReduce.
That being said, like I mentioned it does dive into the details of MapReduce and it goes out of scope of what you need to know for systems design interviews.
So only go read the white paper if you're really interested in MapReduce.
But so they introduced the MapReduce model in that white paper and it was exactly that, it was a framework that allowed engineers or systems administrators to process very large data sets that were spread across hundreds or thousands of machines, so in a distributed setting, very efficiently, quickly and in a fault-tolerant manner.
Now the premise behind the MapReduce model, the premise that these engineers operated on was that the Grand majority of data processing tasks could be split up or refactored so to speak into two steps; a Map step and a Reduce step.
And these two steps of the Map and the Reduce were inspired by the Map and Reduce functions that a lot of functional programming languages have.
So depending on your background, you might actually be familiar already with the concept of the Map and a Reduce.
They're a little bit different when we're talking about just a programming language, but for example if you come from a Python background or JavaScript background, you're certainly familiar with the Map and Reduce functions.
Now here in the context of MapReduce and in a distributed system setting, the Map and Reduce are a little bit different as we'll see in a minute.
But so, like I said, these engineers realized that most data processing tasks could be split up into these two steps and they created a library that would basically allow you or allow an engineer or a systems administrator to process huge data sets in the order of terabytes, spread across hundreds of thousands of machines very easily.
So how did or how does this MapReduce model work? Well, basically you've got your data and here we assume that we are in a distributed system, more specifically we have a distributed file system, in other words our data is stored across multiple machines.
So in the diagram here that I've drawn out we've got some piece of data, here this yellow data, that's split out across four machines, and we're gonna apply on the data that's stored across these four machines, we're gonna apply a Map function or a Map program.
And this Map function is gonna transform this data into key value pairs.
And the fact that these are key value pairs is gonna be very important and I'll get into that in a little bit.
These key value pairs are gonna be the intermediate key value pairs because they live here at the intermediate step in our entire MapReduce job or MapReduce process.
And then these key value pairs are gonna be shuffled around and reorganized in a way that makes sense, and here in this final step the Reduce step, they're gonna be reduced into some final output, and this output might be some file that you'll then use elsewhere in your system.
And so at this point, as you can see, the concept of MapReduce is actually pretty simple.
You've got a data set that's spread across multiple machines you have some Map function that you the engineer or systems administrator is gonna specify, that Map function is gonna transform your data set into intermediate values, these key value pairs, and then these key value pairs as for being reorganized in some way are gonna be reduced in some final step into some final output.
We're gonna look at an example in a second to make this a lot clear, but first a few points that are very important to note about MapReduce.
The first one is that when we're dealing with a MapReduce model, we assume that we have a distributed file system, this means that we've got some large data set that is split up into chunks, these chunks are likely replicated and spread out across multiple machines in the order of hundreds or thousands of machines and then our distributed file system has some sort of central control plane that is aware of everything going on in the MapReduce job or process.
What that means is that the central control plane knows where all of the chunks of data reside, it knows how to communicate with the various machines that store all of this data, it knows how to communicate with the machines that are gonna be performing the Map operations, you sometimes call them worker machines, same thing for the Reduce step, it knows how to communicate with the various reduce workers, it knows where your output is gonna live and so on and so forth, that's the first thing that's important to note about the MapReduce model.
The second thing that's important to note is that oftentimes because we're dealing with very large datasets, we don't actually want to move the large data set.
We want to leave the data set wherever it resides, so all these chunks of data we've let them live where they currently live on their respective machines, and what we do is we have the Map functions or the Map programs move to the data and operate on the data locally.
So instead of grabbing all the data and maybe aggregating it and moving it elsewhere, we send the Map programs to the data, just in order to avoid moving all of this very large data.
The third thing that's very important to note about the MapReduce model, is that the key value pairs structure of the data especially in this intermediate step is very important.
The reason it's important is because naturally when you perform a Reduce, when you reduce data values, especially data values that come from multiple chunks of the same data set, because remember all these chunks of data here are chunks of the same large data set, so when you reduce a bunch of data values that come from the same data set you're likely looking for some sort of commonality in these various pieces of data and this will become very clear once we dive into the example here, but this is why the key value pairs structure of this intermediate data here is very important.
Because when you've got key value pairs, then naturally you've got some keys that are gonna be common, some keys are gonna be the same up here and down here, and you can then aggregate them together and reduce them into one single meaningful value based on that key or relevant to that key.
Now the fourth thing that's very important to note about the MapReduce model is that one of the main things that this model tries to accomplish is to handle faults, to handle failures.
Like for instance, if there's a network partition or a machine failure.
In order to handle machine failures, what a MapReduce job is gonna do is it's basically just gonna re-perform a Map operation or Reduce operation where a failure occurred.
So for example, imagine that up here this step here like the first Map, something went wrong here, like maybe here when we were creating this intermediate data this intermediate KV pair or set of KV pairs, maybe there was some sort of network partition, and in this case what our central control plane, the central control plane that we mentioned earlier, what it would do is it would just re-perform the Map, it would re-perform the Map and that would regive us these kV pairs up here, and then they would move on to the Reduce step and we would get our final output.
Now what that assumes is that our Map function is idempotent that's really important.
When we're talking about the MapReduce model, we almost always assume or rather we almost always require that the Map function and that the Reduce function be idempotent, in other words if we repeat a Map function or Reduce function multiple time, we need the outcome to be the same regardless of how many times we've repeated that Map function or that Reduce function.
So that's really important the idempotency of your Map and Reduce functions.
And then the final point that's very important to note about the MapReduce model, and hopefully this point is clear by now, is that as the engineer or the systems administrator who's dealing with a MapReduce job, the main thing that you care about is what Map function you're gonna specify, what Reduce function you're gonna specify, and what the various inputs and outputs of those functions is gonna be, that's really all you care about.
So you care about what your Map is gonna be, what the input data is gonna look like, which is gonna be the input of the Map function, what the output intermediate key value pairs are gonna look like, which are gonna be the output of the Map, then how these intermediate key value pairs are gonna be reorganized or reshuffled in a meaningful way such that these worker nodes here that perform the Reduce step can perform it optimally or easily, and so typically this is gonna mean aggregating all of the key value pairs for a specific key like k one, for example, in one worker node of the ones with another like k two in another worker node and so on and so forth.
And then these intermediate key value pairs are gonna be the input to your Reduce function and you're of course gonna have to be very aware of what the output of your Reduce function is, because that's gonna be your final output, what you want.
But so as you can see this framework simplifies a lot of things for engineers, that just means that engineers have to worry about what the various inputs and outputs of their data is gonna be, which is what they were concerned with in the first place when they thought of processing a data set and that's it.
They don't have to worry about all of the intricacies of processing a data set in a distributed system, because that's when the MapReduce framework or rather the MapReduce library at this point, 'cause here by the way I'm not only describing the concept of MapReduce, the MapReduce model, but I'm also implying that there's some sort of implementation of this model.
So there's some sort of library that you might be able to use as an engineer or as a systems administrator that's gonna do all of this for you, and all that you'll have to do is specify the Map, the Reduce and of course be aware of the various inputs and outputs of these two functions.
But okay at this point we've explained at length what the MapReduce model is, let's actually go through an example, so I'm gonna undo these two lines, let's go through an example of a MapReduce job, and for this we're gonna use the canonical MapReduce example the example that was actually first presented in that white paper that those Google engineers published in 2004, and that example is counting the number of occurrences of words in some large text file.
So imagine that you've aggregated a bunch of Wikipedia pages or Amazon books and you wanna count the number of occurrences of every word in this data set.
So for the purpose of this example, I'm gonna use a much smaller data set, we're gonna be dealing with just four chunks of data, these text files are gonna only have letters, so the letter is A, B and C and we're gonna wanna count the number of occurrences of the letter A, of the letter B and of the letter C.
So as you can imagine in this very simple example what our Map function might look like is some sort of loop that's gonna iterate through our text files at each data set and is gonna tally up the number of occurrences of a particular letter, or of every letter present in these various chunks.
And all of these map operations are gonna happen in parallel so here for the first piece of data, what this would likely return would be something like, A colon two, so this would be a key value pair.
A pointing two, now by the way you're depending on how you set up your MapReduce job things might look a little bit different.
So here I've made it such that all of the data in this chunk is processed and aggregated and then returned in this KV pair.
I could have also done it such that as my Map function iterates or processes this data chunk, it emits a stream of key value pairs.
So instead of having A pointing two, I could have made it such that this Map function would emit A pointing to one, then another A pointing to one.
So the first occurrence of A, it emits A pointing to one, a key value pair of A one, by the way here I'm saying A pointing to one 'cause I'm just describing this conceptually, but maybe this would be just written in a file, maybe this would be written literally in some text file where the text file is called A and it's got one line with one on it.
This really depends on your preference as the engineer or the systems administrator.
You have to decide what you want your inputs and outputs to look like, you have to decide what you want your Maps and your Reduces to look like.
But so here I'm gonna undo what I wrote and I'll go back to the first example where we've got A pointing to two, so I've aggregated or counted, tallied up all of the occurrences of the letter A, and as all other letters in this data chunk there's only A here, and I returned a set of KV pairs, there's only one here, a pointing to two.
Then in the mean time, 'cause remember all of these Maps are happening in parallel, we've got here the second Map that counts one A and one B, so we're gonna have A pointing to one and B pointing to one.
Then here we've got two A's and one C, so I'll write A pointing to two and C pointing to one.
And then we've got three B's here, so B pointing to three.
Now at this point we've got all of our intermediate key value pairs and we're gonna perform this intermediary step, the shuffle step, which by the way is often overlooked because again from a high level, what you're really just doing is a Map and a Reduce, but this intermediary step of shuffling the intermediate key value pairs is actually pretty important, because if you're trying to optimize operations in your distributed system, then you're gonna wanna make sure that all of the key value pairs for the key A or for the key B are on the same worker node at the Reduce step, otherwise things might get a little bit complicated or you might not be taking advantage of certain optimizations.
But so the point is here in our particular example during the shuffle step, we would likely have all the key value pairs with the key A aggregated up here in this worker node, all the key value pairs with the key B aggregated here in the middle in this worker node, and then all the key value pairs with the key C down here in this worker node.
And so if I write everything down, it would likely be A two up here, A one up here and A two, you can see that we had two key value pairs with the letter A up here and another one here, so A two, A one, A two, A two, A one, A two, then all of the B ones would be here, so here we would have B one and B three.
And then here we would just have C one, and then finally in the Reduce step, the Reduce step would actually count up all of these occurrences and it would write the final values to these output files.
And so we would likely have A five, 'cause there are five occurrences of the letter A up here in this output file and then we would have B four and C one, and this Reduce step really just did some pretty simple logic of going through all of the key value pairs that each of these worker nodes have and tallying up all of their numbers.
And since all the key value pairs specific to a particular key are organized together, they're grouped up together after our shuffle step, this Reduce step is very simple.
And so just like that we've counted the total number of occurrences of every letter or every word if we're talking about a legitimate example in some large data set that spread out across hundreds or thousands of machines.
And as you can probably imagine this MapReduce model can be applied to all sorts of problems.
Like for example, imagine you had a bunch of YouTube videos stored in some data set and you had metadata about those YouTube videos, and you wanted to get maybe the total number of views or of likes per user or per YouTube channel.
You might use a MapReduce job to get that data from that huge data set of YouTube videos.
Or maybe imagine if you had some huge data set of logs in your system, so imagine you had a bunch of logs from various services in your system like logs from your payment service, logs from your authentication service and you wanted to maybe count the total number of logs per service, or the total number of logs in some interval of time.
You might use a MapReduce job to accomplish just that.
Ultimately as those Google engineers said in the white paper that they published in 2004, there are so many data processing tasks that can be expressed in the MapReduce model.
And so at this point let's dive into a very simple code example of yet another data processing tasks that MapReduce lends itself really well to accomplishing.
So for this example, the data set that we're dealing with consists of latencies, you could imagine that we've aggregated latencies for various network requests on AlgoExpert for instance, and we have these latencies in two text files, these text files live under two different directories host1 and host2.
These two directories even though they're part of the same file system here 'cause they're on my computer, they're meant to mimic a distributed file system, so you could imagine that in a real distributed system host1 would be one machine, host2 would be a second machine and you would likely have hundreds or even thousands of these machines.
And we have all these latencies, 100 latencies in the first file, another 100 in the second file.
And we're gonna run a MapReduce job that is gonna count the total number of latencies that are over 10 seconds and that are under 10 seconds.
It's gonna count to these two numbers and it's gonna store them in a results.txt file, under this reduce results directory.
And so spoiler alert, this is the result, you've got 136 latencies over 10 seconds and 64 latencies under 10 seconds and these latencies are in milliseconds.
So this is what we want out of this MapReduce job.
Now let's look at how we're actually gonna implement it, what our Map and Reduce functions are gonna look like and even our shuffle function.
And here needless to say, I've preemptively run this MapReduce job, 'cause we have the output here and we've got a bunch of intermediate files, you'll see in a second but normally of course this would be an empty file or even an inexistent file.
And so taking a look at our map file, because this is the first step of the MapReduce job, the first thing that we're gonna do is, well we have this Map function that's declared here and we are gonna get our Map input passing in latencies.txt, and if we look at this function this getMapInput function which comes from our MapReduce module here, MapReduce getMapInput takes in a filename latencies.txt and it grabs the path of that filename in the host, and the host here is gonna be a process environment variable, so it'll be host1 or host2, so this function here grabs the path like host1/latencies.txt or host2/latencies.txt, and then it uses the FS JavaScript library which allows you to interact with your filesystem to read the file or to read the contents of the file located at this path.
So basically getting the Map input just consists of reading these latencies files and getting these contents.
And so we get these contents and then we pass them to this function, the Map function and this function is gonna be called on the text or the contents of these two files, right? So this is mimicking what a real MapReduce job would do, it would perform the Map function or the Map operation on your various machines that store the various chunks of your data set.
And here it's a very simple function, we split the content with respect to the newline character.
So this gets us all the lines in the various files, and then for every line we parse the line as an integer using the parseInt method and JavaScript, this gives us effectively the latency.
And if the latency is less than 10,000 milliseconds or less than 10 seconds, we emit a Map result.
Now we pass in a string under 10 seconds and the number one, you'll see what that means in a second, otherwise we emit the Map result with over 10 seconds and the number one.
So if we look at what this emitMapResult function is, it's again in our MapReduce file here, emitMapResult grabs the host, again the current host, and goes into map results directory in the host, so host1/map_results host2/map_results, and then it grabs the key that we pass it, so the key is gonna be under 10 seconds or over 10 seconds, these two strings are gonna be our two keys at the intermediate step.
And it grabs those two keys, creates a file out of them or creates this is the file name that it's gonna write to and then it appends in that file using the FS library the value that we pass.
And the value that we pass is literally just the number one, so here unlike in the word count example that we covered previously where we actually tallied up the number of letters in a particular host, remember we had A pointing to two in the first machine and so on and so forth, here all that we're doing is writing to these intermediate files that are named after under 10 seconds or over 10 seconds, and we're writing a bunch of lines of the number one.
So if we look at these map results in host1, it looks like we've got 70 lines of the number one in over 10 seconds and here in under 10 seconds we've got 30 lines of the number one.
So that means that in this latencies file here, there were 70 latencies over 10 seconds and 30 latencies under 10 seconds.
So now we're at the intermediate step, where we've got these intermediate key value pairs, where the keys are these file names, like over 10 seconds or under 10 seconds.
The values are the contents of these files, and we have them for each host.
So we have over 10 seconds under 10 seconds in host1 and both of these files in host2, right? And these files are different, they're relevant to the particular host.
To like here there are 66 latencies over 10 seconds versus 70 here.
And so now we go to the shuffle step.
With the shuffle step we're gonna grab both of our hosts, this is again gonna be just a process environment variable and for every host we grab the file names in the map results directory stored at that host, so we grab over 10 seconds and under 10 seconds for every host, you can imagine if we had 10 hosts, then we would have 20 files.
For every fileName in this list of file names and this list of file names is just over 10 seconds and under 10 seconds for every host.
But so for every one of these file names, we grab the key from the fileName, 'cause the key is actually over 10 seconds minus the .txt, so we remove the .txt extension.
We read the contents of the file, so we read the contents of over 10 seconds in host1, and then we write to our final map results, add the key those contents.
So basically our shuffle step what it does, and here this is where this example is a little bit contrived, right? This is not necessarily the example that we covered previously and this is not necessarily how a MapReduce job would function in a real distributed setting.
But what we've done is we've shuffled these intermediate key value pairs and aggregated them under a single map results directory in the same two files but that just have both of the results.
So over 10 seconds now has 136 lines with the number one and under 10 seconds has 64 lines of the number one, which is the number of lines here 30 plus 34 hence 64.
And so now finally we're at the Reduce step of our MapReduce job.
The Reduce step is gonna get the ReduceInputs, and this is gonna be again a method in our MapReduce module here.
So this method grabs the file names in the map results directory, so in our final directory here then for every fileName in these file names, so for over 10 seconds and under 10 seconds again it grabs the key, it reads the contents of that key, and then it pushes to our IReduceInputs arrays of key value pairs.
The key is the key that we got from the fileName and then the value is gonna be the contents of the file that we just read, and here we do a little filter because if we split by line break then you might have an empty line at the end here, so we parse that out.
And the idea is that we will now have very palatable input for our Reduce function, we'll have a key and the contents here that are just an array basically of the number ones, and then in the Reduce step, when we actually call Reduce on these inputs, any where the first value of the input is the key and the second value of the input is the list of values.
We grab the count of values by just doing values.length, the total number of ones for each key, and we emit the Reduce result passing in these two values and the Reduce result that we emit here we grab the fileName which is just results.txt or end file and we append it to that file, we write to that file the key plus the value, and that is how we get the final output here.
So we've effectively run our Map which grabs the various latencies files, and emits just the number one with a specific key depending on the value of the latency, that then gets written to a special file under the particular host, then we shuffle these intermediary key value pairs that we have with these files and the bunch of ones, we aggregate then in this final directory here map results and then for the reduce part, we read these map results, grab the keys and grab the total number of ones or rather the list of ones, once we've parsed them from the files and in the Reduce step we just grab the count of ones values.lengths, the total number of ones.length and we emit that result which just gets written to this results.txt file.
And so finally in this run script that we've got here, we actually execute or launch the entire MapReduce job, so we've got a bunch of removals here just to clean up all these files if we've previously run this job and then we first run the Map step on both hosts, so we declare host1 and host2 as our process environment variables and we run map.js then we wait for these Map steps to complete, then we run the shuffle step, and remember in the shuffle step we also needed the hosts, so here we have the hosts specified as a process environment variable again.
And then finally we run the Reduce step and then just show the Reduce results.
And so this script here is meant to replicate what that central control plane of your distributed file system would do.
This is the place here that knows where the data lives, this is the place that determines what the Map and Reduce functions are gonna be, where the programs are gonna live and so on and so forth.
And so if we actually run this script here, you can see that I ran it before which is what gave us all of these files, and if we run it again we do the exact same thing it overwrites all the files, you didn't actually see that happen but you can trust that it did and here it finally shows what our results are, 136 over 10 seconds and 64 under 10 seconds.
So this was a fairly contrived example of a MapReduce job, once again this is not done in a distributed system here so it's of course gonna be a little bit funky but you can imagine what this would look like in a distributed system.
And so this is what MapReduce is, it's an incredibly useful concept or framework when you're processing large datasets in a distributed setting and it's definitely gonna be a tool that you're gonna want in your tool belt when you jump into a systems design interview.
With that I hope that you found this video informative and I'll see you in the next one.